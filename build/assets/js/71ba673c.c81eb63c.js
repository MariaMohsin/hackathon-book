"use strict";(self.webpackChunkai_native_book=self.webpackChunkai_native_book||[]).push([[763],{3627:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"nvidia-isaac/digital-twins","title":"Digital Twins","description":"What is a Digital Twin?","source":"@site/docs/nvidia-isaac/digital-twins.md","sourceDirName":"nvidia-isaac","slug":"/nvidia-isaac/digital-twins","permalink":"/docs/nvidia-isaac/digital-twins","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/docs/docs/nvidia-isaac/digital-twins.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Digital Twins","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim Setup","permalink":"/docs/nvidia-isaac/isaac-sim-setup"},"next":{"title":"Understanding ROS 2","permalink":"/docs/category/understanding-ros-2"}}');var t=i(4848),s=i(8453);const a={title:"Digital Twins",sidebar_position:3},o="Digital Twins",l={},c=[{value:"What is a Digital Twin?",id:"what-is-a-digital-twin",level:2},{value:"Creating a Digital Twin",id:"creating-a-digital-twin",level:2},{value:"Step 1: Model the Physical Robot",id:"step-1-model-the-physical-robot",level:3},{value:"Step 2: Import into Isaac Sim",id:"step-2-import-into-isaac-sim",level:3},{value:"Step 3: Configure Sensors",id:"step-3-configure-sensors",level:3},{value:"Step 4: Simulate Control Commands",id:"step-4-simulate-control-commands",level:3},{value:"Physics Tuning for Realism",id:"physics-tuning-for-realism",level:2},{value:"Matching Real Robot Behavior",id:"matching-real-robot-behavior",level:3},{value:"Friction and Traction",id:"friction-and-traction",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Training Data from Simulation",id:"training-data-from-simulation",level:3},{value:"Validation: Sim-to-Real Transfer",id:"validation-sim-to-real-transfer",level:2},{value:"Testing Algorithms in Simulation First",id:"testing-algorithms-in-simulation-first",level:3},{value:"Common Challenges",id:"common-challenges",level:2},{value:"Challenge 1: Physics Don&#39;t Match",id:"challenge-1-physics-dont-match",level:3},{value:"Challenge 2: Sensor Simulation Inaccurate",id:"challenge-2-sensor-simulation-inaccurate",level:3},{value:"Challenge 3: Computational Cost",id:"challenge-3-computational-cost",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"digital-twins",children:"Digital Twins"})}),"\n",(0,t.jsx)(n.h2,{id:"what-is-a-digital-twin",children:"What is a Digital Twin?"}),"\n",(0,t.jsx)(n.p,{children:"A digital twin is a virtual replica of a physical robot that mirrors its structure, behavior, and capabilities. It enables you to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Simulate"})," robot behavior before deployment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Train"})," AI models safely"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Troubleshoot"})," issues without hardware"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Optimize"})," designs and algorithms"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"creating-a-digital-twin",children:"Creating a Digital Twin"}),"\n",(0,t.jsx)(n.h3,{id:"step-1-model-the-physical-robot",children:"Step 1: Model the Physical Robot"}),"\n",(0,t.jsx)(n.p,{children:"Export your robot design in URDF or CAD format:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<robot name="my_robot">\r\n  \x3c!-- Base link --\x3e\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.3 0.2 0.1"/>\r\n      </geometry>\r\n      <material name="aluminum">\r\n        <color rgba="0.8 0.8 0.8 1"/>\r\n      </material>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="0.3 0.2 0.1"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="5.0"/>\r\n      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.2"/>\r\n    </inertial>\r\n  </link>\r\n  \r\n  \x3c!-- Wheel links --\x3e\r\n  <link name="wheel_fl">\r\n    <visual>\r\n      <geometry>\r\n        <cylinder radius="0.1" length="0.05"/>\r\n      </geometry>\r\n    </visual>\r\n  </link>\r\n</robot>\n'})}),"\n",(0,t.jsx)(n.h3,{id:"step-2-import-into-isaac-sim",children:"Step 2: Import into Isaac Sim"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.core import World\r\nfrom omni.isaac.core.robots import Robot\r\n\r\nworld = World()\r\n\r\n# Load robot from URDF\r\nrobot = Robot(\r\n    prim_path="/World/my_robot",\r\n    usd_path="path_to_robot.usd"  # Convert URDF to USD first\r\n)\r\n\r\n# Add to world\r\nworld.scene.add(robot)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"step-3-configure-sensors",children:"Step 3: Configure Sensors"}),"\n",(0,t.jsx)(n.p,{children:"Add all sensors from the physical robot:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from omni.isaac.sensor import Lidar, Imu\r\n\r\n# Match physical robot\'s sensor configuration\r\nlidar = Lidar(\r\n    prim_path="/World/my_robot/lidar",\r\n    translation=[0, 0, 0.3],\r\n    frequency=10.0,\r\n    max_range=25.0\r\n)\r\n\r\nimu = Imu(\r\n    prim_path="/World/my_robot/imu",\r\n    translation=[0, 0, 0.15]\r\n)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"step-4-simulate-control-commands",children:"Step 4: Simulate Control Commands"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class DigitalTwinController:\r\n    def __init__(self, robot):\r\n        self.robot = robot\r\n        self.joint_positions = {}\r\n    \r\n    def set_joint_target(self, joint_name, position):\r\n        """Set target position for a joint"""\r\n        joint = self.robot.get_joint(joint_name)\r\n        joint.set_target_position(position)\r\n    \r\n    def set_wheel_velocity(self, left_vel, right_vel):\r\n        """Set wheel velocities (for differential drive)"""\r\n        self.robot.get_joint("wheel_left").set_target_velocity(left_vel)\r\n        self.robot.get_joint("wheel_right").set_target_velocity(right_vel)\r\n    \r\n    def get_joint_state(self, joint_name):\r\n        """Get current joint state"""\r\n        joint = self.robot.get_joint(joint_name)\r\n        return {\r\n            \'position\': joint.get_position(),\r\n            \'velocity\': joint.get_velocity(),\r\n            \'effort\': joint.get_effort()\r\n        }\n'})}),"\n",(0,t.jsx)(n.h2,{id:"physics-tuning-for-realism",children:"Physics Tuning for Realism"}),"\n",(0,t.jsx)(n.h3,{id:"matching-real-robot-behavior",children:"Matching Real Robot Behavior"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# 1. Measure physical robot properties\r\n# - Mass, moment of inertia\r\n# - Friction coefficients\r\n# - Motor torque/speed limits\r\n\r\n# 2. Configure in simulation\r\nphysics_context = PhysicsContext()\r\n\r\n# Set material properties to match real materials\r\nrubber_material = {\r\n    'static_friction': 0.7,\r\n    'dynamic_friction': 0.5,\r\n    'restitution': 0.1\r\n}\r\n\r\n# Apply to wheels\r\nwheel = world.scene.get_object(\"wheel_fl\")\r\nwheel.get_prim().GetAttribute(\"physxMaterial:staticFriction\").Set(0.7)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"friction-and-traction",children:"Friction and Traction"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'def calibrate_friction(digital_twin, physical_robot):\r\n    """Adjust simulation friction to match real robot"""\r\n    \r\n    # Test: push robot and measure deceleration\r\n    velocities = []\r\n    \r\n    for t in range(100):\r\n        digital_twin.step(render=False)\r\n        vel = digital_twin.get_linear_velocity()\r\n        velocities.append(vel)\r\n    \r\n    # Calculate deceleration in simulation\r\n    sim_decel = (velocities[0] - velocities[-1]) / len(velocities)\r\n    \r\n    # Compare with physical robot deceleration\r\n    # Adjust friction until they match\n'})}),"\n",(0,t.jsx)(n.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,t.jsx)(n.h3,{id:"training-data-from-simulation",children:"Training Data from Simulation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import cv2\r\nimport numpy as np\r\nfrom pathlib import Path\r\n\r\nclass SyntheticDataGenerator:\r\n    def __init__(self, world, output_dir):\r\n        self.world = world\r\n        self.output_dir = Path(output_dir)\r\n        self.output_dir.mkdir(exist_ok=True)\r\n    \r\n    def generate_dataset(self, num_samples=1000):\r\n        """Generate labeled dataset for training"""\r\n        \r\n        images = []\r\n        labels = []\r\n        \r\n        for i in range(num_samples):\r\n            # Randomize scene\r\n            self.randomize_objects()\r\n            self.randomize_lighting()\r\n            \r\n            # Capture image\r\n            self.world.step(render=True)\r\n            image = self.world.camera.get_rgb()\r\n            \r\n            # Generate labels\r\n            detections = self.detect_objects_in_image(image)\r\n            \r\n            # Save\r\n            cv2.imwrite(f"{self.output_dir}/image_{i:06d}.png", image)\r\n            self.save_labels(f"{self.output_dir}/label_{i:06d}.json", detections)\r\n            \r\n            images.append(image)\r\n            labels.append(detections)\r\n        \r\n        return images, labels\r\n    \r\n    def randomize_objects(self):\r\n        """Random object placement and orientation"""\r\n        import random\r\n        \r\n        for obj in self.world.scene.get_all_objects():\r\n            obj.set_position([\r\n                random.uniform(-1, 1),\r\n                random.uniform(-1, 1),\r\n                random.uniform(0.5, 2)\r\n            ])\r\n    \r\n    def randomize_lighting(self):\r\n        """Vary lighting conditions"""\r\n        import random\r\n        \r\n        light = self.world.scene.get_light("main_light")\r\n        light.set_intensity(random.uniform(0.5, 2.0))\n'})}),"\n",(0,t.jsx)(n.h2,{id:"validation-sim-to-real-transfer",children:"Validation: Sim-to-Real Transfer"}),"\n",(0,t.jsx)(n.h3,{id:"testing-algorithms-in-simulation-first",children:"Testing Algorithms in Simulation First"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class SimToRealValidator:\r\n    def __init__(self, sim_world, real_robot):\r\n        self.sim_world = sim_world\r\n        self.real_robot = real_robot\r\n    \r\n    def test_algorithm(self, algorithm, test_scenarios):\r\n        """Test algorithm in both simulation and reality"""\r\n        \r\n        sim_results = []\r\n        real_results = []\r\n        \r\n        for scenario in test_scenarios:\r\n            # Test in simulation\r\n            self.sim_world.reset_to_scenario(scenario)\r\n            sim_result = algorithm.run(self.sim_world)\r\n            sim_results.append(sim_result)\r\n            \r\n            # Test on real robot\r\n            self.real_robot.reset_to_scenario(scenario)\r\n            real_result = algorithm.run(self.real_robot)\r\n            real_results.append(real_result)\r\n        \r\n        # Compare results\r\n        correlation = self.compute_correlation(sim_results, real_results)\r\n        return correlation\r\n    \r\n    def compute_correlation(self, sim_results, real_results):\r\n        """Calculate how well simulation matches reality"""\r\n        import numpy as np\r\n        return np.corrcoef(sim_results, real_results)[0, 1]\n'})}),"\n",(0,t.jsx)(n.h2,{id:"common-challenges",children:"Common Challenges"}),"\n",(0,t.jsx)(n.h3,{id:"challenge-1-physics-dont-match",children:"Challenge 1: Physics Don't Match"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Simulation behaves differently from real robot"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Carefully tune mass, friction, and actuator limits"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"challenge-2-sensor-simulation-inaccurate",children:"Challenge 2: Sensor Simulation Inaccurate"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Simulated sensor readings don't match real sensors"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Add noise and latency to match real sensor characteristics"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'def add_realistic_noise(sensor_reading):\r\n    """Add noise to match real sensor"""\r\n    import numpy as np\r\n    \r\n    # Add Gaussian noise\r\n    noise = np.random.normal(0, sensor_noise_std)\r\n    \r\n    # Add latency (simulate delayed reading)\r\n    delay = np.random.choice([0, 1, 2])  # 0-2 frames delayed\r\n    \r\n    return sensor_reading + noise - delay\n'})}),"\n",(0,t.jsx)(n.h3,{id:"challenge-3-computational-cost",children:"Challenge 3: Computational Cost"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Problem"}),": Simulation too slow for real-time testing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Solution"}),": Use GPU acceleration, reduce simulation resolution"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Start Simple"}),": Build minimal digital twin first"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Validate Incrementally"}),": Compare simulation to real robot step-by-step"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Use Domain Randomization"}),": Vary parameters to improve real-world robustness"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Monitor Discrepancies"}),": Track differences between sim and reality"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Iterative Refinement"}),": Continuously improve digital twin accuracy"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"You can now use digital twins to train AI algorithms and create advanced robotics applications."})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var r=i(6540);const t={},s=r.createContext(t);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);