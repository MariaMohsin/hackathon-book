"use strict";(self.webpackChunkai_native_book=self.webpackChunkai_native_book||[]).push([[337],{8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>o});var i=r(6540);const s={},a=i.createContext(s);function t(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(a.Provider,{value:n},e.children)}},8872:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"robot-nervous-system/vision-sensors","title":"Vision Sensors","description":"Overview","source":"@site/docs/robot-nervous-system/vision-sensors.md","sourceDirName":"robot-nervous-system","slug":"/robot-nervous-system/vision-sensors","permalink":"/docs/robot-nervous-system/vision-sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/docs/docs/robot-nervous-system/vision-sensors.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Vision Sensors","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Sensors Overview","permalink":"/docs/robot-nervous-system/sensors-overview"},"next":{"title":"Motion Sensors","permalink":"/docs/robot-nervous-system/motion-sensors"}}');var s=r(4848),a=r(8453);const t={title:"Vision Sensors",sidebar_position:2},o="Vision Sensors",l={},c=[{value:"Overview",id:"overview",level:2},{value:"RGB Cameras",id:"rgb-cameras",level:2},{value:"How They Work",id:"how-they-work",level:3},{value:"Specifications",id:"specifications",level:3},{value:"Applications",id:"applications",level:3},{value:"Example: Capturing Images with OpenCV",id:"example-capturing-images-with-opencv",level:3},{value:"Depth Cameras",id:"depth-cameras",level:2},{value:"How They Work",id:"how-they-work-1",level:3},{value:"Popular Depth Cameras",id:"popular-depth-cameras",level:3},{value:"Point Cloud Data",id:"point-cloud-data",level:3},{value:"Applications",id:"applications-1",level:3},{value:"Thermal Cameras",id:"thermal-cameras",level:2},{value:"Characteristics",id:"characteristics",level:3},{value:"Limitations",id:"limitations",level:3},{value:"Event Cameras",id:"event-cameras",level:2},{value:"How They Work",id:"how-they-work-2",level:3},{value:"Advantages",id:"advantages",level:3},{value:"Disadvantages",id:"disadvantages",level:3},{value:"Best Practices for Vision Sensors",id:"best-practices-for-vision-sensors",level:2},{value:"Camera Mounting",id:"camera-mounting",level:3},{value:"Lighting Conditions",id:"lighting-conditions",level:3},{value:"Image Processing Pipeline",id:"image-processing-pipeline",level:3},{value:"Camera Calibration",id:"camera-calibration",level:2},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"vision-sensors",children:"Vision Sensors"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Vision sensors provide the most information-rich perception capability for robots. They capture visual data that can be processed for object detection, navigation, and manipulation tasks."}),"\n",(0,s.jsx)(n.h2,{id:"rgb-cameras",children:"RGB Cameras"}),"\n",(0,s.jsx)(n.h3,{id:"how-they-work",children:"How They Work"}),"\n",(0,s.jsx)(n.p,{children:"RGB cameras capture three color channels (Red, Green, Blue) at each pixel location."}),"\n",(0,s.jsx)(n.h3,{id:"specifications",children:"Specifications"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Resolution"}),": 640x480, 1280x720, 1920x1080, or higher"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Frame Rate"}),": 30 FPS, 60 FPS, or higher for fast motion"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Field of View"}),": Wide (greater than 90 degrees) for panoramic, normal (~50 degrees), or narrow (less than 30 degrees) for detail"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"applications",children:"Applications"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Object detection and recognition"}),"\n",(0,s.jsx)(n.li,{children:"Visual odometry for navigation"}),"\n",(0,s.jsx)(n.li,{children:"Quality inspection"}),"\n",(0,s.jsx)(n.li,{children:"Gesture recognition"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-capturing-images-with-opencv",children:"Example: Capturing Images with OpenCV"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import cv2\r\n\r\n# Open default camera\r\ncap = cv2.VideoCapture(0)\r\n\r\nwhile True:\r\n    ret, frame = cap.read()\r\n    \r\n    if ret:\r\n        # Process frame\r\n        cv2.imshow('Camera Feed', frame)\r\n        \r\n        if cv2.waitKey(1) & 0xFF == ord('q'):\r\n            break\r\n    else:\r\n        break\r\n\r\ncap.release()\r\ncv2.destroyAllWindows()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"depth-cameras",children:"Depth Cameras"}),"\n",(0,s.jsx)(n.h3,{id:"how-they-work-1",children:"How They Work"}),"\n",(0,s.jsx)(n.p,{children:"Depth cameras measure distance to objects by:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Time-of-Flight (ToF)"}),": Measure light travel time"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Structured Light"}),": Project patterns and analyze reflections"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stereo Vision"}),": Compare images from two cameras"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"popular-depth-cameras",children:"Popular Depth Cameras"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Intel RealSense D435"}),"\n",(0,s.jsx)(n.li,{children:"Microsoft Kinect"}),"\n",(0,s.jsx)(n.li,{children:"Luxonis OAK-D"}),"\n",(0,s.jsx)(n.li,{children:"Basler depth cameras"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"point-cloud-data",children:"Point Cloud Data"}),"\n",(0,s.jsx)(n.p,{children:"Depth cameras produce point clouds - 3D coordinates of visible surfaces:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import open3d as o3d\r\n\r\n# Load point cloud\r\npcd = o3d.io.read_point_cloud("cloud.ply")\r\n\r\n# Visualize\r\no3d.visualization.draw_geometries([pcd])\r\n\r\n# Filter outliers\r\ncl, ind = pcd.remove_statistical_outlier(\r\n    nb_neighbors=20, std_ratio=2.0\r\n)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"applications-1",children:"Applications"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"3D object detection and grasping"}),"\n",(0,s.jsx)(n.li,{children:"3D mapping and reconstruction"}),"\n",(0,s.jsx)(n.li,{children:"Obstacle avoidance"}),"\n",(0,s.jsx)(n.li,{children:"Human pose estimation"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"thermal-cameras",children:"Thermal Cameras"}),"\n",(0,s.jsx)(n.h3,{id:"characteristics",children:"Characteristics"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Detect heat radiation (IR spectrum)"}),"\n",(0,s.jsx)(n.li,{children:"Work in darkness"}),"\n",(0,s.jsx)(n.li,{children:"Useful for predictive maintenance"}),"\n",(0,s.jsx)(n.li,{children:"Good for search and rescue"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"limitations",children:"Limitations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Lower resolution than RGB"}),"\n",(0,s.jsx)(n.li,{children:"Affected by reflective surfaces"}),"\n",(0,s.jsx)(n.li,{children:"Cannot see through glass"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"event-cameras",children:"Event Cameras"}),"\n",(0,s.jsx)(n.h3,{id:"how-they-work-2",children:"How They Work"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Record pixel-level brightness changes instead of frames"}),"\n",(0,s.jsx)(n.li,{children:"Very low latency (microseconds)"}),"\n",(0,s.jsx)(n.li,{children:"High dynamic range"}),"\n",(0,s.jsx)(n.li,{children:"Sparse, event-based output"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"advantages",children:"Advantages"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Extreme sensitivity to motion"}),"\n",(0,s.jsx)(n.li,{children:"Works in high-speed scenarios"}),"\n",(0,s.jsx)(n.li,{children:"Low power consumption"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"disadvantages",children:"Disadvantages"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Difficult to process (specialized algorithms)"}),"\n",(0,s.jsx)(n.li,{children:"Limited availability and cost"}),"\n",(0,s.jsx)(n.li,{children:"Smaller field of view than RGB"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"best-practices-for-vision-sensors",children:"Best Practices for Vision Sensors"}),"\n",(0,s.jsx)(n.h3,{id:"camera-mounting",children:"Camera Mounting"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Mount at appropriate height and angle for task"}),"\n",(0,s.jsx)(n.li,{children:"Avoid backlighting"}),"\n",(0,s.jsx)(n.li,{children:"Protect from dust and moisture"}),"\n",(0,s.jsx)(n.li,{children:"Secure firmly to prevent vibration"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"lighting-conditions",children:"Lighting Conditions"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ensure adequate illumination for RGB cameras"}),"\n",(0,s.jsx)(n.li,{children:"Avoid specular reflections on glossy surfaces"}),"\n",(0,s.jsx)(n.li,{children:"Use infrared LEDs with depth cameras for better performance"}),"\n",(0,s.jsx)(n.li,{children:"Consider different lighting for different tasks"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"image-processing-pipeline",children:"Image Processing Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def process_camera_image(frame):\r\n    # 1. Capture image\r\n    # 2. Undistort (correct lens distortion)\r\n    undistorted = cv2.undistort(frame, camera_matrix, dist_coeffs)\r\n    \r\n    # 3. Convert color space if needed\r\n    hsv = cv2.cvtColor(undistorted, cv2.COLOR_BGR2HSV)\r\n    \r\n    # 4. Apply filters\r\n    blurred = cv2.GaussianBlur(hsv, (5, 5), 0)\r\n    \r\n    # 5. Detect features\r\n    edges = cv2.Canny(blurred, 100, 200)\r\n    \r\n    # 6. Post-process\r\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\r\n    result = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\r\n    \r\n    return result\n"})}),"\n",(0,s.jsx)(n.h2,{id:"camera-calibration",children:"Camera Calibration"}),"\n",(0,s.jsx)(n.p,{children:"Every camera needs calibration to correct lens distortion:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import cv2\r\nimport numpy as np\r\n\r\n# Detect checkerboard corners in calibration images\r\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\r\n\r\n# Calculate camera matrix\r\nret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\r\n    objpoints, imgpoints, gray.shape[::-1], None, None\r\n)\n"})}),"\n",(0,s.jsx)(n.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom sensor_msgs.msg import Image\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\n\r\nclass CameraNode(rclpy.node.Node):\r\n    def __init__(self):\r\n        super().__init__('camera_node')\r\n        self.pub = self.create_publisher(Image, 'camera/image_raw', 10)\r\n        self.bridge = CvBridge()\r\n        self.cap = cv2.VideoCapture(0)\r\n        \r\n        self.timer = self.create_timer(0.033, self.capture_and_publish)\r\n    \r\n    def capture_and_publish(self):\r\n        ret, frame = self.cap.read()\r\n        if ret:\r\n            msg = self.bridge.cv2_to_imgmsg(frame, encoding=\"bgr8\")\r\n            self.pub.publish(msg)\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = CameraNode()\r\n    rclpy.spin(node)\r\n    node.destroy_node()\r\n    rclpy.shutdown()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.p,{children:["Learn about ",(0,s.jsx)(n.a,{href:"motion-sensors",children:"Motion Sensors"})," and then explore ",(0,s.jsx)(n.a,{href:"sensor-integration",children:"Sensor Integration"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);