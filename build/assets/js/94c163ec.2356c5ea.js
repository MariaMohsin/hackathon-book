"use strict";(self.webpackChunkai_native_book=self.webpackChunkai_native_book||[]).push([[153],{2595:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"robot-nervous-system/sensor-integration","title":"Sensor Integration","description":"Overview","source":"@site/docs/robot-nervous-system/sensor-integration.md","sourceDirName":"robot-nervous-system","slug":"/robot-nervous-system/sensor-integration","permalink":"/docs/robot-nervous-system/sensor-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/docs/docs/robot-nervous-system/sensor-integration.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Sensor Integration","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Actuators","permalink":"/docs/robot-nervous-system/actuators"},"next":{"title":"NVIDIA Isaac","permalink":"/docs/category/nvidia-isaac"}}');var i=n(4848),a=n(8453);const t={title:"Sensor Integration",sidebar_position:5},l="Sensor Integration",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Integration Architecture",id:"integration-architecture",level:2},{value:"Hardware Layer",id:"hardware-layer",level:3},{value:"Communication Protocols",id:"communication-protocols",level:3},{value:"I2C (Inter-Integrated Circuit)",id:"i2c-inter-integrated-circuit",level:4},{value:"SPI (Serial Peripheral Interface)",id:"spi-serial-peripheral-interface",level:4},{value:"Serial (UART)",id:"serial-uart",level:4},{value:"CAN Bus",id:"can-bus",level:4},{value:"Multi-Sensor Data Processing Pipeline",id:"multi-sensor-data-processing-pipeline",level:2},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Publishing Sensor Data",id:"publishing-sensor-data",level:3},{value:"Subscribing to Sensor Data",id:"subscribing-to-sensor-data",level:3},{value:"Sensor Synchronization",id:"sensor-synchronization",level:2},{value:"Common Integration Challenges",id:"common-integration-challenges",level:2},{value:"Challenge 1: Different Sensor Rates",id:"challenge-1-different-sensor-rates",level:3},{value:"Challenge 2: Sensor Latency",id:"challenge-2-sensor-latency",level:3},{value:"Challenge 3: Sensor Noise",id:"challenge-3-sensor-noise",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const r={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"sensor-integration",children:"Sensor Integration"})}),"\n",(0,i.jsx)(r.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(r.p,{children:"Sensor integration combines multiple sensors into a unified system that provides accurate, reliable perception for robot control and decision-making."}),"\n",(0,i.jsx)(r.h2,{id:"integration-architecture",children:"Integration Architecture"}),"\n",(0,i.jsx)(r.h3,{id:"hardware-layer",children:"Hardware Layer"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{children:"Sensors \u2500\u2500\u2192 Microcontroller/SBC \u2500\u2500\u2192 Main Computer\r\n            (Polling, interrupts)    (ROS 2 nodes)\n"})}),"\n",(0,i.jsx)(r.h3,{id:"communication-protocols",children:"Communication Protocols"}),"\n",(0,i.jsx)(r.h4,{id:"i2c-inter-integrated-circuit",children:"I2C (Inter-Integrated Circuit)"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Simple, uses only 2 wires (SDA, SCL)"}),"\n",(0,i.jsx)(r.li,{children:"Multiple sensors on same bus"}),"\n",(0,i.jsx)(r.li,{children:"Slower speed (100-400 kHz typical)"}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import smbus\r\n\r\nbus = smbus.SMBus(1)  # Bus 1 for RPi\r\naddress = 0x68\r\n\r\n# Write to sensor\r\nbus.write_byte_data(address, 0x6B, 0)\r\n\r\n# Read from sensor\r\ndata = bus.read_byte_data(address, 0x3B)\n"})}),"\n",(0,i.jsx)(r.h4,{id:"spi-serial-peripheral-interface",children:"SPI (Serial Peripheral Interface)"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Faster than I2C (up to 10 MHz)"}),"\n",(0,i.jsx)(r.li,{children:"Requires separate chip select (CS) line per sensor"}),"\n",(0,i.jsx)(r.li,{children:"More wires needed"}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import spidev\r\n\r\nspi = spidev.SpiDev()\r\nspi.open(0, 0)  # Bus 0, Device 0\r\nspi.max_speed_hz = 1000000\r\n\r\n# Transfer data\r\ndata = spi.xfer2([0x00, 0x00])\n"})}),"\n",(0,i.jsx)(r.h4,{id:"serial-uart",children:"Serial (UART)"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Simple point-to-point communication"}),"\n",(0,i.jsx)(r.li,{children:"Widely supported"}),"\n",(0,i.jsx)(r.li,{children:"Limited to one device per port"}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import serial\r\n\r\nser = serial.Serial('/dev/ttyUSB0', 115200)\r\ndata = ser.readline()\n"})}),"\n",(0,i.jsx)(r.h4,{id:"can-bus",children:"CAN Bus"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsx)(r.li,{children:"Robust, used in vehicles and industrial robotics"}),"\n",(0,i.jsx)(r.li,{children:"Good for real-time distributed systems"}),"\n"]}),"\n",(0,i.jsx)(r.h2,{id:"multi-sensor-data-processing-pipeline",children:"Multi-Sensor Data Processing Pipeline"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"class RobotPerceptionSystem:\r\n    def __init__(self):\r\n        self.camera = CameraModule()\r\n        self.imu = IMUModule()\r\n        self.encoders = EncoderModule()\r\n        self.lidar = LidarModule()\r\n        \r\n        self.last_readings = {}\r\n        self.fused_state = None\r\n    \r\n    def acquire_sensor_data(self):\r\n        \"\"\"Collect data from all sensors\"\"\"\r\n        readings = {\r\n            'camera': self.camera.read(),\r\n            'imu': self.imu.read(),\r\n            'encoders': self.encoders.read(),\r\n            'lidar': self.lidar.read(),\r\n            'timestamp': time.time()\r\n        }\r\n        return readings\r\n    \r\n    def preprocess(self, readings):\r\n        \"\"\"Filter and normalize sensor data\"\"\"\r\n        processed = {}\r\n        \r\n        # Apply noise filters\r\n        processed['imu'] = self.filter_imu(readings['imu'])\r\n        processed['encoders'] = self.filter_encoders(readings['encoders'])\r\n        \r\n        # Undistort camera image\r\n        processed['camera'] = self.undistort_image(readings['camera'])\r\n        \r\n        return processed\r\n    \r\n    def fuse_data(self, processed):\r\n        \"\"\"Combine sensor data for better estimates\"\"\"\r\n        # Use Kalman filter to fuse encoder and IMU\r\n        position = self.kalman_filter(\r\n            processed['encoders'],\r\n            processed['imu']\r\n        )\r\n        \r\n        # Detect objects with camera + lidar\r\n        objects = self.detect_objects(\r\n            processed['camera'],\r\n            processed['lidar']\r\n        )\r\n        \r\n        return {\r\n            'position': position,\r\n            'objects': objects,\r\n            'raw_sensors': processed\r\n        }\r\n    \r\n    def filter_imu(self, imu_data):\r\n        \"\"\"Apply complementary filter\"\"\"\r\n        # Combines accelerometer and gyroscope\r\n        alpha = 0.98\r\n        filtered = (alpha * self.last_readings.get('gyro', imu_data['gyro']) +\r\n                   (1 - alpha) * imu_data['accel'])\r\n        return filtered\r\n    \r\n    def detect_objects(self, image, lidar):\r\n        \"\"\"Combine vision and lidar for 3D object detection\"\"\"\r\n        # Run object detection on image\r\n        boxes = self.object_detector.predict(image)\r\n        \r\n        # Associate with lidar points\r\n        objects_3d = []\r\n        for box in boxes:\r\n            # Find lidar points within image box projection\r\n            depth = self.get_lidar_depth(box, lidar)\r\n            obj = {\r\n                'class': box.class_name,\r\n                'bbox_2d': box,\r\n                'distance': depth\r\n            }\r\n            objects_3d.append(obj)\r\n        \r\n        return objects_3d\r\n\r\ndef main():\r\n    perception = RobotPerceptionSystem()\r\n    \r\n    while True:\r\n        # 1. Acquire data from all sensors\r\n        raw_data = perception.acquire_sensor_data()\r\n        \r\n        # 2. Preprocess (filter, normalize)\r\n        processed = perception.preprocess(raw_data)\r\n        \r\n        # 3. Fuse sensor data\r\n        fused = perception.fuse_data(processed)\r\n        \r\n        # 4. Use fused data for control decision\r\n        publish_robot_state(fused)\n"})}),"\n",(0,i.jsx)(r.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,i.jsx)(r.h3,{id:"publishing-sensor-data",children:"Publishing Sensor Data"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, Imu, LaserScan\r\nfrom geometry_msgs.msg import Pose\r\n\r\nclass SensorPublisher(Node):\r\n    def __init__(self):\r\n        super().__init__('sensor_publisher')\r\n        \r\n        self.camera_pub = self.create_publisher(Image, 'camera/image_raw', 10)\r\n        self.imu_pub = self.create_publisher(Imu, 'imu/data', 10)\r\n        self.lidar_pub = self.create_publisher(LaserScan, 'scan', 10)\r\n        \r\n        # Timer callback at 50 Hz\r\n        self.timer = self.create_timer(0.02, self.publish_sensors)\r\n    \r\n    def publish_sensors(self):\r\n        # Publish camera image\r\n        image_msg = self.read_camera()\r\n        self.camera_pub.publish(image_msg)\r\n        \r\n        # Publish IMU data\r\n        imu_msg = self.read_imu()\r\n        self.imu_pub.publish(imu_msg)\r\n        \r\n        # Publish lidar\r\n        scan_msg = self.read_lidar()\r\n        self.lidar_pub.publish(scan_msg)\n"})}),"\n",(0,i.jsx)(r.h3,{id:"subscribing-to-sensor-data",children:"Subscribing to Sensor Data"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"class SensorSubscriber(Node):\r\n    def __init__(self):\r\n        super().__init__('sensor_subscriber')\r\n        \r\n        self.create_subscription(Image, 'camera/image_raw', \r\n                                self.image_callback, 10)\r\n        self.create_subscription(Imu, 'imu/data', \r\n                                self.imu_callback, 10)\r\n    \r\n    def image_callback(self, msg):\r\n        # Process camera image\r\n        cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\r\n        # ... perform object detection, etc.\r\n    \r\n    def imu_callback(self, msg):\r\n        # Process IMU data\r\n        acc_x = msg.linear_acceleration.x\r\n        # ... perform calculations\n"})}),"\n",(0,i.jsx)(r.h2,{id:"sensor-synchronization",children:"Sensor Synchronization"}),"\n",(0,i.jsx)(r.p,{children:"Important for multi-sensor fusion:"}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"import message_filters\r\n\r\nclass SensorSynchronizer(Node):\r\n    def __init__(self):\r\n        super().__init__('sensor_sync')\r\n        \r\n        # Subscribe to multiple topics\r\n        image_sub = message_filters.Subscriber(self, Image, 'camera/image_raw')\r\n        imu_sub = message_filters.Subscriber(self, Imu, 'imu/data')\r\n        \r\n        # Synchronize messages (approximate time synchronization)\r\n        ts = message_filters.ApproximateTimeSynchronizer(\r\n            [image_sub, imu_sub],\r\n            queue_size=10,\r\n            slop=0.1  # Allow 100ms time difference\r\n        )\r\n        \r\n        ts.registerCallback(self.synchronized_callback)\r\n    \r\n    def synchronized_callback(self, image_msg, imu_msg):\r\n        # Both messages arrived at approximately the same time\r\n        self.process_fused_data(image_msg, imu_msg)\n"})}),"\n",(0,i.jsx)(r.h2,{id:"common-integration-challenges",children:"Common Integration Challenges"}),"\n",(0,i.jsx)(r.h3,{id:"challenge-1-different-sensor-rates",children:"Challenge 1: Different Sensor Rates"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Problem"}),": Sensors update at different frequencies"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Solution"}),": Use buffering and interpolation"]}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'class SensorBuffer:\r\n    def __init__(self, max_size=100):\r\n        self.buffer = collections.deque(maxlen=max_size)\r\n    \r\n    def add(self, timestamp, data):\r\n        self.buffer.append((timestamp, data))\r\n    \r\n    def interpolate_at(self, target_time):\r\n        """Get interpolated value at target time"""\r\n        # Find two surrounding samples\r\n        # Linearly interpolate between them\r\n        pass\n'})}),"\n",(0,i.jsx)(r.h3,{id:"challenge-2-sensor-latency",children:"Challenge 2: Sensor Latency"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Problem"}),": Delayed sensor readings cause control lag"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Solution"}),": Predict sensor data into the future"]}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:'def predict_state(current_state, velocity, dt):\r\n    """Predict where robot will be in dt seconds"""\r\n    predicted = current_state + velocity * dt\r\n    return predicted\n'})}),"\n",(0,i.jsx)(r.h3,{id:"challenge-3-sensor-noise",children:"Challenge 3: Sensor Noise"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Solution"}),": Apply appropriate filters"]}),"\n"]}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-python",children:"class LowPassFilter:\r\n    def __init__(self, cutoff_frequency, sampling_rate):\r\n        self.alpha = 1 / (1 + 2*3.14159*cutoff_frequency/sampling_rate)\r\n        self.last_value = 0\r\n    \r\n    def filter(self, new_value):\r\n        self.last_value = self.alpha * new_value + (1-self.alpha)*self.last_value\r\n        return self.last_value\n"})}),"\n",(0,i.jsx)(r.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(r.p,{children:"Now that sensors are integrated, you can build complete robotic systems with autonomous control."})]})}function u(e={}){const{wrapper:r}={...(0,a.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>t,x:()=>l});var s=n(6540);const i={},a=s.createContext(i);function t(e){const r=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(a.Provider,{value:r},e.children)}}}]);